## Overview:

[ ] 1. Find models for code generation (3 / 4) use models recommended in DiverseVul
    [ ] 1.1 As the DiverseVul paper explained the best models are those that are
            pre-trained on code datasets.
    [ ] 1.2 So models are going to be GPT3.5, GPT-preview, Code models from other developers
    [ ] 1.3 https://huggingface.co/teknium/Replit-v2-CodeInstruct-3B
    [ ] 1.4 https://huggingface.co/teknium/OpenHermes-2.5-Mistral-7B

[X] 2. Find known vulnerability datasets
    [ ] 2.0 Use datasets from the DiverseVul paper
    [ ] 2.1 Generate test websites with vulnerabilities embedded in them.
    [ ] 2.2 Ask Shin if he's with using vulnerability testing on his app.
[ ] 3. Create a scafolded model using tools like:
    [ ] 3.1 CoT specified for code readability and understanding
    [ ] 3.2 Table **unsure why this would be of any help?**
[ ] 4. Steps on test:
    [ ] 4.0 Train and then test on the datasets provided
    [ ] 4.1 Run scafolded model on pwned website and see how far it can go?
    [ ] 4.2 Generate vulnerability report of target using the model using 2
    [ ] 4.3 Generate malware to attack such a vulnerability using 3
    [ ] 4.4 Run malware against target
[ ] 5. Compare the results and see which model is better
[ ] 6. Compare against Lynx for vulnerability detection
[ ] 7. Generate a report

## Scafolded model structure

### Structure for pwnable

1. Read instructions, copy ssh, and then copy all files into directory
2. Prompt GPT to give access to directory to execute commands
3. Subsequent prompt follow a scafolded structure to be found
4. See if he is correct

### Training datasets
1. NatGen
2. Reveal
3. DeVign
4. **DiverseVul**
5. VulDeePecker
6. BigVul
7. CrossVul
8. CVEFixes.

# Ideas

## Chain of thought prompting guided towards code

## Issues to address

CoT Prompt formation

1. Bridging object: How to represent them in the context of code?
    Are they the variables? The AST structure? Other?
2. Language template: Extra stuff this can be explanation of snippets of code
revolving around the main vars?


# Dataset DiverseVul

## Issues to address

Failure to generalize to all projects outside of training data. 
This is seen in the scores on the F1 scheme.
## Question: Is this due to a lack of understanding of data depth?
Solution:
1. Using AST structures to recognize similar code structures from
the training data?
2. Full repo scan and CoT to have a better understanding of the
code structure.


